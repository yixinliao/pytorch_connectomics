# All other configurations are set by default. If you want to add new config options,
# please modify ../connectomics/config/config.py
SYSTEM:
  NUM_GPUS: 4
  NUM_CPUS: 8
MODEL:
  ARCHITECTURE: 'unet_residual_3d'
  INPUT_SIZE: [8, 256, 256]
  OUTPUT_SIZE: [8, 256, 256]
  IN_PLANES: 1
  OUT_PLANES: 3
  LOSS_OPTION: [['WeightedBCE', 'DiceLoss']]
  LOSS_WEIGHT: [[1.0, 1.0]]
  TARGET_OPT: ['1']
  WEIGHT_OPT: [['1', '0']]
  FILTERS: [32, 64, 128, 256, 256] 
# To use the same data processing and model training protocol for
# different datasets, we leave the image and label paths blank here
# and use command line options. Please check: ../scripts/main.py
DATASET:
  IMAGE_NAME: '<name/of/image (h5py volumes)>'
  LABEL_NAME: '<name/of/label (h5py volumes)>'
  INPUT_PATH: '<path/to/data>'
  OUTPUT_PATH: 'outputs/synaptic_polarity/'
  PAD_SIZE: [4, 128, 128]
  REJECT_SAMPLING:
    SIZE_THRES: 1000
    P: 0.95
SOLVER:
  LR_SCHEDULER_NAME: "WarmupMultiStepLR"
  BASE_LR: 0.001
  ITERATION_STEP: 1
  ITERATION_SAVE: 5000
  ITERATION_TOTAL: 50000
  SAMPLES_PER_BATCH: 8
  STEPS: (45000, 47500)
MONITOR:
  VIS_OPT: [1, 16]
INFERENCE:
  IMAGE_NAME: '<name/of/image (h5py volumes)>'
  OUTPUT_PATH: 'outputs/synaptic_polarity/test'
  AUG_MODE: 'mean'
  AUG_NUM: 4
  OUTPUT_NAME: 'syn_polarity_pred.h5'
  STRIDE: [4, 128, 128]
  SAMPLES_PER_BATCH: 16
  INPUT_SIZE: [8, 256, 256]
  OUTPUT_SIZE: [8, 256, 256]
  PAD_SIZE: [4, 128, 128]